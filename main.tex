% vim: spell spelllang=es:
\input{preamble.tex}

\usepackage[bottom]{footmisc}

\usepackage{amsmath}

\title{IA Búsqueda local}
\author{%
    Aleix Boné\\
    Alex Herrero\\
    Moisés Balcells
}
\date{%
Marzo 2020
}

% MARIA TERESA ABAD: <mabad@cs.upc.edu>


\begin{document} 

\newtheorem{hyp}{Hipótesis}[section]
\newtheorem*{hyp*}{Hipótesis}[section]


\thispagestyle{empty}
\clearpage
\setcounter{page}{-1}

\begin{titlepage}
{
    \centering
    \null
    \vfill
    {\Large Inteligencia Artificial\par}
    \vspace{2em}
    {\Huge \bfseries 
    Práctica de búsqueda local
    \par}
    \vspace{2em}
    {\large \scshape 
    Marzo 2020
    \par}
    \vfill
\begin{center}
    
\end{center}
    \vspace{3cm}

    \vfill
    {\raggedleft \large
Aleix Boné Ribó\\
Alex Herrero Pons\\
    Moisés Balcells
        \par}
}
\end{titlepage}

\pagebreak

\thispagestyle{empty}
\clearpage
\setcounter{page}{0}

\tableofcontents

\pagebreak


% La documentación deberá incluir:
% La descripción/justificación de la implementación del estado.
% La descripción/justificación de los operadores que habéis elegido...
% La descripción/justificación de las estrategias para hallar la solución inicial.
% La descripción/justificación de las funciones heurísticas.
% Para cada experimento:    
% • Condiciones de cada experimento
% • Resultados del experimento
% • Qué esperabais y qué habéis obtenido    
% • Comparaciones
% • Comentarios adicionales que os parezcan adecuados.
% Comparación entre los resultados obtenidos con Hill Climbing y Simulated Annealing (no olvidéis explicar cómo habéis ajustado los parámetros para este último algoritmo).
% Respuestas razonadas a las preguntas del enunciado.

% Descripción del problema detallada



\section{Descripción del problema}

%Primeramente vamos a describir

\subsection{Elementos del problema}

Los elementos del problema que consisten en un conjunto de servidores y usuarios distribuidos de manera geográfica. Cada
uno de estos servidores tiene a su vez un conjunto de ficheros. Cada fichero esta identificado por un identificador
único y varios servidores pueden tener copias de un mismo fichero (replicaciones) pero no necesariamente todos
los servidores tienen todos los ficheros. Cuando un usuario hace una petición (de un fichero)
un servidor central que se encarga de distribuir las peticiones realizadas por los usuarios. Este servidor tiene información
sobre el contenido de cada uno de los servidores e indica al usuario a que
servidor acceder para obtener el fichero que ha pedido. El servidor que gestiona las peticiones sabe también el tiempo
de transmisión de cada uno de los servidores a cada usuario. Al igual que los ficheros, los servidores, los usuarios y
las peticiones que estos realizan se identifican mediante IDs.

\subsection{Notas importantes}

Los ficheros son servidos de manera secuencial y los tiempos que se tarda en servir una petición no pueden superar a los 5000ms ni bajar de los 100ms. Un usuario puede hacer una o múltiples peticiones de distintos ficheros y un fichero puede ser pedido muchas veces por distintos usuarios.

\subsection{Objetivo}

El objetivo del problema es asignar para cada petición realizada el servidor que servirá el archivo al usuario.
Debemos tener en cuenta que se considera una mejor solución aquella que tiene un menor tiempo de transmisión total y aquella que tiene las cargas de los servidores distribuidas de manera equilibrada. Ya que si únicamente tuvieras en cuenta que fuera el menor tiempo de transmisión total posible las cargas de los servidores no serian equilibradas cosa que no nos interesa.

Así pues, una solución del problema es una asignación para cada petición a un servidor. Debido a que queremos encontrar
una solución que minimiza el tiempo de carga de los servidores y equilibre el trabajo de estos se trata de un problema
de optimización.

\subsection{Variables}%
\label{ssec:variables}

% numero de estados: prop to ~ NREQ*USERS*NREP (TODO: comentar esto en algun sitio)

%nrep/nserv <= 0.5

Las variables que afectan al problema y a las que nos referiremos en el resto de la práctica son las siguientes:

\begin{enumerate}
    \item \texttt{USERS}: número de usuarios.
    \item \texttt{NSERV}: número de servidores.
    \item \texttt{REQUESTS}: máximo numero de peticiones por usuario.
    \item \texttt{NREP}: número de replicaciones mínimo de cada fichero.
\end{enumerate}

Tal como hemos dicho en la sección previa, una solución es una asignación de cada petición a un servidor. Considerando
esto y con las variables del problema que hemos definido tenemos un espacio de soluciones de:
\begin{align}
\texttt{REQUESTS*USERS*REPLICACIONES} \\
\texttt{NREP} \leq \texttt{REPLICACIONES} \leq \texttt{NSERV}
\end{align}

El espacio de soluciones es por lo tanto muy grande para valores relativamente pequeños de usuarios, peticiones y
servidores, por lo que una búsqueda exhaustiva no seria eficiente. Dada una solución válida,
podemos explorar soluciones vecinas cambiando uno de los servidores de una de las peticiones. 

\section{Implementación del estado}

Para lograr el estado inicial con el cuál hemos ejecutado los experimentos hicimos distintas versiones del estado inicial hasta que nos quedamos con la que creíamos que era mejor.

\subsection{Primera versión}

La primera versión de la implementación planteada era muy simple y consistía guardar un array con los identificadores
de los servidores que enviarían el fichero de la petición correspondiente al índice del array, es decir para cada
petición en el array guardábamos el servidor que iba a responder esa petición.

Esta versión era eficiente en memoria debido a los pocos datos que se almacenan. Pero al empezar a implementar las heurísticas
nos percatamos que se tenían que realizar muchos cálculos para obtener los valores de las heurísticas. Esto hacia que la
ejecución fuera muy lenta y se calculaban muchos datos de forma repetida.

\subsection{Segunda versión}
Para evitar la repetición de cálculos al computar las heurísticas de la primera versión decidimos añadir al estado
dos variables adicionales: una que guardaba el tiempo total de todas las transmisiones asignadas y un array con
el tiempo de transmisión de cada petición para el servidor asignado en el estado.

Con esta implementación, el cálculo de las funciones heurísticas tardaba menos que en la primera versión,
debido a que hora guardamos variables que antes no guardábamos las cuales nos facilitan el cálculo de las funciones heurísticas.
Sin embargo la mejora no era muy sustancial ya que seguíamos requiriendo bastantes cálculos que se podían evitar.
En cuanto a la eficiencia en la memoria esta sigue siendo eficiente pero menos que antes.

\subsection{Versión definitiva}

Finalmente decidimos guardar también el tiempo de transmisión de los ficheros de cada servidor, ya que para la primera
heurística necesitábamos el tiempo de los servidores, no de las peticiones individualmente.
Puesto que los IDs de los servidores no estaban delimitados, tuvimos que usar un Map de entero entero donde guardamos para cada ID de servidor
el tiempo total de transmisión de las peticiones que se le asignaban. De este modo el cálculo de las heurísticas era
mucho más rápido y el tiempo de ejecución se reducía considerablemente.

Esta versión final, nos proporciona el menor tiempo de ejecución de todas las versiones anteriores, y teniendo en cuenta que mantiene una eficiencia en memoria aceptable, para el tipo de problemas al que nos enfrentamos creemos que es la mejor opción. 


% primero solo guardavamos para cada req el id del server
% desupes guardamos tambien los tiempos de las req
% finalmente guardamos los tiempos de las req i de los servidores

\section{Operadores que hemos elegido}%
\label{sec:operadores_elegidos}

Definimos dos operadores, uno que cambiaba la asignación de uno de los servidores que daba una petición por otro distinto.
La otra operadora era muy similar, hacia lo mismo pero con la restricción de que solo se podía hacer cambios a servidores
que no se hubieran probado antes para ese archivo.

La segunda operadora reduce mucho la ramificación respecto a la primera y a medida que se avanza en la búsqueda se va
reduciendo aún más. Por consiguiente debería ser más rápida que la primera operación, pero es muy restrictiva y seguramente
no permita llegar a estados de solución tan buenos como los alcanzables por la primera operación.

\section{Estrategias para hallar la solución inicial}%
\label{sec:estrat_sol}

Implementamos dos estrategias para hallar la solución inicial, una muy naïve que cogía el primer servidor
de la lista de servidores que tenia el fichero para cada petición y otra greedy que cogía para cada petición
el servidor que tenía menor tiempo de transmisión al usuario. La naïve tenía muchos problemas, el principal
que al seleccionar siempre el primer servidor de la lista de servidores que tenían el fichero, la carga de
trabajo se distribuía siempre en los mismos servidores para cada fichero.

\section{Funciones heurísticas}

Implementamos dos funciones heurísticas tal y como pedía el enunciado. La primera minimiza el tiempo de transmisión
de los ficheros para el servidor que necesita mas tiempo para transmitir sus peticiones. La segunda minimiza
el tiempo total de transmisión de los ficheros pero con la restricción de que los tiempos de transmisión de los servidores
han de ser lo más similares posibles entre ellos

\subsection{Primera heurística}

Para la primera heurística simplemente debemos computar el tiempo de transmisión de los ficheros de cada servidor y hallar
el máximo. En nuestra primera versión del estado esto suponía recorrer todas las peticiones y calcular para cada una de
ellas el tiempo de transmisión del servidor al usuario y sumar-lo al tiempo de cada servidor. Después recorríamos los tiempos
de los servidores y encontrábamos el máximo. Este método era lineal en el número de peticiones y de servidores y se tenia
que computar para cada rama de cada estado por el que pasábamos, era por lo tanto muy poco eficiente.

Con la versión definitiva del estado al tener un Map con el tiempo de cada servidor nos ahorramos el paso de
recorrer y computar el tiempo de todas las peticiones y solo tenemos que encontrar el máximo entre los servidores, 
esta operación es lineal en el número de servidores y aunque no lo parezca es mucho más eficiente que la primera
implementación ya que el número de servidores es mucho menor al número de peticiones y no tenemos que hacer
llamadas a las funciones de \texttt{DistFS}.

\subsection{Segunda heurística}

La segunda heurística es más compleja ya que se tienen que considerar dos factores: la minimización del tiempo total
de transmisión y el equilibrio de cargas entre servidores.

Nos decidimos por calcular el tiempo total de transmisión y multiplicar-lo por la desviación estándar de los tiempos
de transmisión de cada servidor.

\section{Experimentos}

\subsection{Influencia de los operadores}

Tal como se explica en la sección~\ref{sec:operadores_elegidos}, implementamos dos versiones de operadores,
una que permitía acceder a todo el espacio de búsqueda y otra más restrictiva que evitaba repetir combinaciones
de fichero servidor. Usamos los parametros que se muestran en la tabla~\ref{tab:ex1}:

\begin{table}[H]
    \caption{Parametros y resultados del experimento 1}%
    \label{tab:ex1}
    \begin{center}
    \begin{tabular}{lr}
    \toprule
    Parámetro & valor \\
    \midrule
    USERS & 200 \\
    NSERV & 50 \\
    NREP & 5 \\
    REQUESTS & 5\\
    \bottomrule
    \end{tabular}
    \hspace{2em}
    \begin{tabular}{ccr}
    \toprule
    Operador & Generador & Heurística \\
    \midrule
    \multirow{2}{*}{1} & naïve &  91063\\
    {} & greedy & 11758 \\
    \addlinespace[0.5em]
    \multirow{2}{*}{2} & naïve &  49069\\
    {} & greedy & 11947 \\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

%TODO: esto tiene que ser con seed random

\subsection{Influencia de la solución inicial}

%TODO: esto tiene que ser con seed random

Tal como se ha comentado en la sección~\ref{sec:estrat_sol}, implementamos 2 versiones distintas
para generar la solución inicial. Una que cogía el primer servidor de la lista de servidores que daban ficheros
para cada petición y otra que buscaba entre los servidores que tenían el fichero, el que tenía mínimo
tiempo de transmisión para el usuario de la petición.

La primera versión tenía un coste computacional mínimo ya que solo se accedía al primer elemento del
conjunto retornado por \texttt{DistFS.Server.fileLocations(fileID)}. La otra versión tenia que recorrer
todo el conjunto para encontrar el servidor con tiempo de transmisión mínimo, lo que equivale a un coste
lineal en $NREP$ (Número de replicaciones mínima de un fichero).

A pesar de que la segunda versión del generador de estado inicial es mucho más costoso, esta limitado
por $NREP$ que es una constante y no muy grande ($\nicefrac{NREP}{NSERV} <0.5$), por lo que el coste es negligible
y el tener un mejor estado inicial nos permite llegar a un máximo local con menos iteraciones y que
los máximos locales estén más cerca de un máximo local.

Tal como se especifica en el enunciado de la práctica usamos los mismos parámetros que en el experimento
1 y repetimos el experimento 100 veces en el mismo ordenador para minimizar los efectos externos que
pueden afectar al tiempo de ejecución.

\begin{table}[H]
    \caption{$T_{ej}$, TTT y heurística obtenidos con los generadores de estado inicial}%
    \label{tab:ex2}
    \begin{center}
    \input{include/tables/ex2_n}
    \end{center}
\end{table}

Los resultados obtenidos se muestran en la tabla~\ref{tab:ex2}, en ella
podemos apreciar claramente como el generador greedy no solo es significativamente más rápido
que el de elegir el primer servidor que se encuentra sino que también llega a un máximo local con
una heurística menor y un tiempo total de transmisión (TTT) también menor (incluso la desviación
estándar es menor en un orden de magnitud).
Dados los resultados de este experimento decidimos usar el segundo generador para el resto ya que es
mejor en todos los ámbitos analizados.

\subsection{Parámetros para el simulated annealing}

El objetivo de este experimento es ajustar los parámetros del Simulated Annealing para conseguir mejores resultados que con Hill Climbing. 

Hicimos el estudio para el mismo escenario que en los experimentos anteriores, utilizando la función heurística, los operadores y la estrategia de generación de la solución inicial escogidos. Con el fin de facilitar la comparación de resultados también establecimos la semilla del generador de números aleatorios 1234.

Para asegurarnos que la búsqueda llega a converger hemos establecido el número de iteraciones a $10^6$.

La mayor dificultad para ajustarlos es que la única indicación que se tiene son los resultados obtenidos experimentalmente, eso obliga hacer pruebas exhaustivas para ver como se comporta el problema.

%TODO: esto se sale del margen, igual un begin{align*} mejor?
En nuestro caso probamos los valores de $stiter\footnote{Iteraciones por cada cambio de temperatura}=\{100,1000,10000\}$, $k=\{10,100,1000,10000\}$ y $\lambda=\{0.01,0.001,0.0001\}$. %como puedo hacer para que no sean todo ',' y se entienda más?.
Con estos valores esperábamos obtener los mejores resultados con $stiter=10000$, $k=10000$ y $\lambda=0.0001$ aunque preveíamos no ver mucha diferencia entre los distintos valores de \emph{stiter}.

Para cada combinación de parámetros hemos realizado 10 ejecuciones del programa y hemos extraído la media del tiempo total de transmisión. Estos resultados se pueden comparar con claridad en la figura~\ref{fig:ex3_histSA}. %TODO: importar histograma.

\begin{figure}[H]
    \centering
    %\includegraphics{include/plots/ex3_histSA.pdf}
    \includegraphics[width=0.8\textwidth]{example-image-a}%cuantas inches le le pongo?
    % pon como las mias o un poco mas anchas %
     %vale esto para las de linea perf, pero para el histograma que son 3 juntos quedará enenao.
     % pon un poco mas grande si quieres para el hist, pon 6  o 6.5 en vez de 5 i 4 en vez de 3.7
     % lo importante (relativamente pork tampoco queremos perf) es k al hacer el includegrafics no hagamos un resize
     % pork entonces te queda las letras de tamanos distintos en los graficos i es feo.
     % perf. si queda muy peque ya veremos.
     % sisi, es quedtion de prueba i error okk
     %rc('figure', figsize=[5.0, 3.7])
     % yo tengo esto
    \caption{Tiempo de transmisión total para los distintos parámetros.\\ \centerline{(\emph{stiter} = 100 1000 10000)}} %No sé como poner esto!! Así está ok? seh, tampoco hay que tenerlo todo perfect
    % esta mierda da un error muy raro geez
    % yaya pero luego sale bien... :)
    \label{fig:ex3_histSA} %nice pues mejor voy tirando y si hay algo mal al final ya se verá
\end{figure}

Como se puede observar en la gráfica los mejores resultados los hemos obtenido con $stiter=10000$, $k=10000$ y $\lambda=0.01$ con un tiempo total de transmisión medio de 488365.8 ms notablemente menor que el de Hill Climbing (559269 ms). 

Este resultado como se puede comprobar concuerda con nuestra hipótesis inicial en los valores de $stiter$ y $k$, pero en el caso de $\lambda$ nos dio un resultado bastante inesperado, del cual extrajimos que valores demasiado pequeños podían dar peores resultados.

También cabe destacar que por lo general no hay mucha diferencias entre los distintos valores de \emph{stiter}, pero si nos fijamos de nuevo en la figura~\ref{fig:histSA} se ve como en el caso de $k=10000$ y $\lambda=0.01$ se observa una gran diferencia entre $stiter=100$ y los otros valores.

\begin{figure}[H]
    \centering
    %\includegraphics{include/plots/ex3_heu_steps-HC.pdf}
    \includegraphics[width=0.8\textwidth]{example-image-a}
    \caption{Evolución de la heurística (HC)}
    \label{fig:ex3_heu_steps-HC} 
\end{figure}

\begin{figure}[H]
    \centering
    %\includegraphics{include/plots/ex3_heu_steps-10000-10000-0.01.pdf}
    \includegraphics[width=0.8\textwidth]{example-image-a}
    \caption{Evolución de la heurística (SA/ $stiter=10000$, $k=10000$ y $\lambda=0.01$)}
    \label{fig:ex3_heu_steps-10000-10000-0.01} 
\end{figure}

Por otro lado también hemos estudiado la evolución de la heurística utilizada a lo largo del problema. Observando la gráfica~\ref{fig:ex3_heu_steps-10000-10000-0.01} y comparándola con la de Hill Climbing (figura~\ref{fig:ex3_heu_steps-HC} vimos que con los parámetros antes mencionados se obtenía un valor de \emph{heuM} mayor (18261 y  11758 respectivamente).

Curiosamente con parámetros que daban peor tiempo total de transmisión que HC se obtuvo mejor valor de \emph{heuM} como en el caso de $stiter=10000$, $k=10$ y $\lambda=0.001$ (figura~\ref{fig:ex3_heu_steps-1000000-10000-10-0.001}) con un tiempo total de transmisión y \emph{heuM} iguales a 568187.7 y 11359 respectivamente.

\begin{figure}[H]
    \centering
    %\includegraphics{include/plots/ex3_heu_steps-1000000-10000-10-0.001.pdf}
    \includegraphics[width=0.8\textwidth]{example-image-a}
    \caption{Evolución de la heurística (SA/ $stiter=10000$, $k=10$ y $\lambda=0.001$)}
    \label{fig:ex3_heu_steps-1000000-10000-10-0.001} 
\end{figure}
% TODO: importar graficos.

\subsection{Evolución del tiempo de ejecución para valores crecientes de los parámetros}

En estos experimentos estudiamos la evolución del coste de la búsqueda en función del tamaño del
problema. Para ello consideramos 2 parámetros: el número de usuarios que piden ficheros y el número
de servidores.

Retomando lo explicado en la sección~\ref{ssec:variables}, el número de estados del problema es:
\texttt{REQUESTS*USERS*REPLICACIONES}, donde \texttt{REPLICACIONES} esta delimitado por
el número mínimo de replicaciones de un fichero y el número de servidores.

Por lo tanto, el número de estados crece más rápido al aumentar el número de usuarios que al aumentar
el número de servidores. Además tener más servidores implica que es más fácil distribuir la carga de modo
equitativo, por lo que es posible que se llegue más rápidamente a los mínimos locales.

\subsubsection{Número de usuarios que piden ficheros}

\begin{table}[H]
    \caption{Parámetros experimento 4 (Usuarios)}%
    \label{tab:ex4u_par}
    \begin{center}
    \begin{tabular}{lr}
    \toprule
    Parámetro & valor \\
    \midrule
    USERS & $100 \to 1000 \quad (+100)$ \\
    NSERV & 50 \\
    NREP & 5 \\
    REQUESTS & 5\\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

Realizamos los experimentos con los parámetros que se muestra en la tabla~\ref{tab:ex4u_par}. Incrementamos
el número de usuarios dese 100 hasta 1000 en incrementos de 100. Se realizaron 100 repeticiones para
cada valor de usuario, cada uno con una semilla distinta. Se midió el tiempo de ejecución y se calculó la media
y la desviación estándar. Los resultados se muestran en la tabla~\ref{tab:ex4u}:

\begin{table}[H]
    \caption{Resultados del experimento 4 (Usuarios)}%
    \label{tab:ex4u}
    \begin{center}
    \input{include/tables/ex4u}
    \end{center}
\end{table}


\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4_u_mean_time.pdf}
    \caption{Media Experimento 4 (Usuarios)}%
    \label{fig:ex4u_mean}
\end{figure}

A partir de estos resultados generamos una gráfica con las medias obtenidas para cada valor de usuarios (figura~\ref{fig:ex4u_mean}). Se puede apreciar un crecimiento que aparentemente parece cuadrático.

En el boxplot que realizamos (figura~\ref{fig:ex4u}) podemos observar como el tiempo de ejecución
varia mucho a medida que se van incrementando el número de usuarios.

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4_u_time_bplot.pdf}
    \caption{Boxplot $T_{ej}$ del experimento 4 (Usuarios)}%
    \label{fig:ex4u}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4u_time_reg.pdf}
    \caption{Regresión lineal $T_{ej}$ del experimento 4 (Usuarios)}%
    \label{fig:ex4u_reg}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4u_time_reg_2.pdf}
    \caption{Fit polinómico de orden 2 del experimento 4 (Usuarios)}%
    \label{fig:ex4u_reg_poly}
\end{figure}

En las figuras~\ref{fig:ex4u_reg} y \ref{fig:ex4u_reg_poly} podemos ver los resultados de una regresión lineal
sobre los datos obtenidos en el experimento 4 y un \emph{fit} polinómico de grado 2. Se puede observar que la
regresión lineal no modela los datos obtenidos y el valor de $R^2=0.54$ también lo indica. El fit polinómico
se ajusta mejor a los datos aunque los valores residuales para los valores de usuarios entre 100 y 500 son
bastante significativos.

\subsubsection{Número de servidores (Manteniendo el número de replicaciones)}

\begin{table}[H]
    \caption{Parámetros experimento 4 (Servidores)}%
    \label{tab:ex4s_par}
    \begin{center}
    \begin{tabular}{lr}
    \toprule
    Parámetro & valor \\
    \midrule
    USERS & 200 \\
    NSERV & $50 \to 1000 \quad (+50)$ \\
    NREP & 5 \\
    REQUESTS & 5\\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

Realizamos los experimentos de modo análogo al experimento anterior pero variando el número
de servidores desde 50 hasta 1000 en incrementos de 50, los parámetros se muestran en la
tabla~\ref{tab:ex4s_par}. Se realizaron 100 repeticiones para
cada valor del número de servidores, cada uno con una semilla distinta.
Se midió el tiempo de ejecución y se calculó la media
y la desviación estándar. Los resultados se muestran en la tabla~\ref{tab:ex4s}:

\begin{table}[H]
    \caption{Resultados del experimento 4 (Servidores)}%
    \label{tab:ex4s}
    \begin{center}
    \input{include/tables/ex4s}
    \end{center}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4_s_mean_time.pdf}
    \caption{Media Experimento 4 (Servidores)}%
    \label{fig:ex4s_mean}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex4_s_time_bplot_cut.pdf}
    \caption{Experimento 4}%
    \label{fig:ex4s}
\end{figure}

\subsection{Diferencia entre Tiempo total de transmisión y tiempo para hallar la solución (Hill Climbing)}

\subsection{Diferencia entre Tiempo total de transmisión y tiempo para hallar la solución (Simulated Annealing)}

\subsection{Influencia del número de replicaciones de los ficheros}

\begin{table}[H]
    \caption{Parámetros experimento 7}%
    \label{tab:ex4s_par}
    \begin{center}
    \begin{tabular}{lr}
    \toprule
    Parámetro & valor \\
    \midrule
    USERS & 200 \\
    NSERV & 50 \\
    NREP & $5 \to 25 \quad (+5)$ \\
    REQUESTS & 5\\
    \bottomrule
    \end{tabular}
    \end{center}
\end{table}

Para este experimento variamos el número de repeticiones de usuarios de 5 a 25 en incrementos de 5. Se realizaron 100
repeticiones para cada caso. Además, realizamos dos experimentos distintos, uno para cada heurística. En las
siguientes secciones se muestran y analizan con detalle los resultados obtenidos para cada heurística y se hace una
comparación.

\begin{hyp*}
    Un mayor número de replicaciones implica un espacio de búsqueda más grande, por lo que el tiempo de ejecución
    aumentará. Así mismo tener más replicaciones hará que los servidores puedan distribuir mejor sus cargas por
    lo que obtendremos tiempos totales de transmisión menores.
\end{hyp*}

\subsubsection{Primera heurística}
\begin{table}[H]
    \centering
    \caption{Resultados del experimento 7 con la primera heurística}%
    \label{tab:ex7}
    \begin{center}
    \input{include/tables/ex7}
    \end{center}
\end{table}

La tabla~\ref{tab:ex7} muestra los resultados obtenidos en el experimento 7 con la primera heurística. Los
datos se muestran en el gráfico de la figura~\ref{fig:ex7means} en el que se puede apreciar como el tiempo
de ejecución incrementa linealmente con el número de replicaciones y el tiempo total de transmisión disminuye.
\footnote{Notase que para poder visualizar bien las pendientes, los ejes verticales no empiezan en 0}.

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_means.pdf}
    \caption{Medias del experimento 7 con la primera heurística}%
    \label{fig:ex7means}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_time_bplot.pdf}
    \caption{Boxplot del tiempo de ejecución con la primera heurística}%
    \label{fig:ex7time}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_ttt_bplot.pdf}
    \caption{Boxplot del tiempo total de transmisión con la primera heurística}%
    \label{fig:ex7ttt}
\end{figure}

\subsubsection{Segunda heurística}

\begin{table}[H]
    \centering
    \caption{Resultados del experimento 7 con la segunda heurística}%
    \label{tab:ex7_total}
    \begin{center}
    \input{include/tables/ex7_total}
    \end{center}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_means_n.pdf}
    \caption{Medias del experimento 7 con la segunda heurística}%
    \label{fig:ex7means_total}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_time_bplot_n.pdf}
    \caption{Boxplot del tiempo de ejecución con la segunda heurística}%
    \label{fig:ex7time_total}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics{include/plots/ex7_ttt_bplot_n.pdf}
    \caption{Boxplot del tiempo total de transmisión con la segunda heurística}%
    \label{fig:ex7ttt_total}
\end{figure}

\subsection{Conclusión de los experimentos}
    
    
    
\end{document}